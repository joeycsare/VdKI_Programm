{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666a03df",
   "metadata": {},
   "source": [
    "PETERS Gauthier (pega1012) / FIMBEL Nicolas (fini1024)\n",
    "\n",
    "\n",
    "Da Dateien nicht mehr als 256MB in Ilias nicht erlaubt wurden, konnten wir nicht die Bilder mit der Hausarbeit geben. Das Tensorflow Verfahren wird nicht richtig laufen, sowie Merkmale_OpenCV. Die selbst programmierte Verfahren können verwenden werden, da sie die CSV Dateien benutzen, die schon ergestellt wurden. \n",
    "\n",
    "\n",
    "# Merkmale aus Bilder herausziehen und Export als CSV Dokument\n",
    "\n",
    "Mit diesem Programm wollen wir verschiedene Merkmale von den Bilder von Kämme und Bürste erleitern und dann wollen wir eine CSV Datei mit diesen Merkmalen erstellen.\n",
    "\n",
    "## I) Import von Bibliotheken und von den Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3991ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import von Bibliotheken\n",
    "import cv2;\n",
    "import numpy as np;\n",
    "import pathlib;\n",
    "import csv;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733697b0",
   "metadata": {},
   "source": [
    "## II) Pfad der Bilder\n",
    "\n",
    "Anhand der Bibliothek **pathlib** können wir den Pfad der Bilder einfach definieren. Darunter ist der Pfad \"data_dir\" der Pfad des Ordners, der die 2 unter Ordner **Kamm** und **Buerste** enthält.\n",
    "\n",
    "Dan können wir die gesamte Anzahl der Bilder geben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c6aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad der Bilder :  Bilder\\Verfahrenbilder\n",
      "Anzahl von Bilder : 1306\n"
     ]
    }
   ],
   "source": [
    "# Pfad der Bilder \n",
    "data_dir = pathlib.Path(r\"Bilder/Verfahrenbilder\")\n",
    "print(\"Pfad der Bilder : \", data_dir)\n",
    "\n",
    "# Anzahl von Bilder\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print('Anzahl von Bilder :', image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b07771",
   "metadata": {},
   "source": [
    "## III) Erste Bilder zeigen\n",
    "\n",
    "Um die Behandlung der Bilder zu vereinfachen, wir haben die Folgende Etappe gefolgt :\n",
    "- Alle .zip Datei in Ilias herunterladen.\n",
    "- Alle Bilder in das JPG-Format konvertieren und umbennen(mit Hilfe des XnView Softwares).\n",
    "\n",
    "Nach diesen Etappen erhalten wir einen Order **Bilder**, der 2 Unterordner enthält : **Buerste** und **Kamm**. \n",
    "\n",
    "Jetzt benutzen wir die Bibliothek **openCV-Python**, um die erste Bilder zu zeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb25452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bilder\\Verfahrenbilder\\Buerste\\Buerste_0001.jpg\n"
     ]
    }
   ],
   "source": [
    "# Erstes Bild von Bürste zeigen\n",
    "Buerste = list(data_dir.glob('Buerste/*'))  # Ordner der Bilder von Bürste\n",
    "print(str(Buerste[0]))\n",
    "img = cv2.imread(str(Buerste[0]))           # Bild mit OpenCV öfnen\n",
    "cv2.imshow(\"erstes Bild von Buerste\", img)  # Bild zeigen\n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f0167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bilder\\Verfahrenbilder\\Kamm\\Kamm_0004.jpg\n"
     ]
    }
   ],
   "source": [
    "# Erstes Bild von Kamm zeigen\n",
    "Kamm = list(data_dir.glob('Kamm/*'))        # Ordner der Bilder von Kämme\n",
    "print(str(Kamm[3]))\n",
    "img = cv2.imread(str(Kamm[3]))              # Bild mit OpenCV öfnen\n",
    "cv2.imshow(\"erstes Bild von Kamm\", img)     # Bild zeigen\n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84d305",
   "metadata": {},
   "source": [
    "## IV) Bilder skalieren\n",
    "\n",
    "Die Bilder haben verschiedene Herkünfte (Internet, verschiedene Fotoapparate). Deswegen hat jedes Bild ihres eigenes Ausmaß. Wir benutzen also OpenCV, um alle Bilder zu skalieren. \n",
    "\n",
    "Wir wählen ein neues konstantes Ausmaß, dass das selbe für jedes Bild wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062b24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neue Ausmaß der Bilder\n",
    "width = 500            # Breite in Pixel\n",
    "height = 500            # Höhe in Pixel\n",
    "dim = (width, height)   # neues Ausmaß der Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b58abfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST BILD ####\n",
    "img = cv2.imread(str(Buerste[347]))\n",
    "###################\n",
    "\n",
    "imgResized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"Risized\", imgResized)     # Bild zeigen\n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065c421",
   "metadata": {},
   "source": [
    "## V) Merkmale von Bilder identifizieren \n",
    "\n",
    "Zuerst werden wir einen Wert erläutern, der sagt, ob das Bild ein Kamm oder eine Bürste ist. Dieser Wert wird in der letzten Spalte der CSV Datei geschrieben:\n",
    "\n",
    "**- 0 wenn das Bild einen Kamm ist**\n",
    "\n",
    "**- 1 wenn das Bild eine Bürste ist**\n",
    "\n",
    "Dann müssen wir die Bilder erarbeiten, um Merkmale zu identifizieren. Um die Merkmale zu erläutern werden wir eine Probe von Bilder benutzen.\n",
    "\n",
    "### 1. Normierung der Bilder\n",
    "\n",
    "Erstens normieren wir die Bilder, um das Rauschen zu reduzieren und den Kontrast zu verbessern. Tatsächlich reduzieren wir mit der Normierung das Hoch- und Tiefrauschen von der Bilder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3dee81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgNormiert = cv2.normalize(imgResized,None,0,255,cv2.NORM_MINMAX) \n",
    "stack = np.hstack((imgResized, imgNormiert ))       # Beider Bilder in der selben Fenster zeigen\n",
    "\n",
    "cv2.imshow(\"origineles und normiertes Bilder\", stack)     \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a51f6",
   "metadata": {},
   "source": [
    "### 2. Bilder in Grau umwandeln\n",
    "\n",
    "Wir wollen dannach die Kontouren der Bilder suchen. Dazu sollen wir zuerst die Bilder in Grau umwandeln, d.h., dass die Bilder nur mir einer Kanal (statt 3 mit RGB) beschreiben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47241986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bild in Grau umwandeln und zeigen\n",
    "imgGrau = cv2.cvtColor(imgNormiert,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"imgGrau\", imgGrau)     \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791e1f4",
   "metadata": {},
   "source": [
    "### 3. Bilder bilaterale filtern\n",
    "\n",
    "Um die scharfe Kante zu behalten aber das Bilder mehr zu egalisieren benutzen wir das bilaterales Filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843497a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bild filtern und zeigen\n",
    "imgBlur = cv2.bilateralFilter(imgGrau,9,100,100)\n",
    "\n",
    "cv2.imshow(\"imgGrau und imgBlur\", np.hstack((imgGrau, imgBlur)))     \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332ae9a",
   "metadata": {},
   "source": [
    "### 4. Kante Erkennung : Edge detection\n",
    "\n",
    "Wir haben jetzt graue Bilder, die gefiltert wurden. Wir können alsro eine Kante Erkennung durchführen, um alle Kante in jedem Bild zu erkennen. \n",
    "\n",
    "Wir bilden eine Funktion, die den Midianwert des Bildes zuerst berechnent, um dann die Grenze in der *cv2.canny* Funktion automatisch zu bestimmen. \n",
    "\n",
    "In einigen Bilder ist der Farbeunterschied zwischen dem Hinter- und Verdergrund gering. Dazu kann die *cannyEdge* Funktion in diesen Fälle keine Kontur finden. Damit erhielten wir eine Fehlermeldung, wenn wir die größte Konturen suchten. \n",
    "\n",
    "Deshalb haben wir die Funktion erweitert, so dass wir auch diese Fälle betrachten könnten. Tatsächlich soll die obere und untere Grenze (upper und lower) kleiner sein. Wir haben also eine Grenze definiert, so dass wir immer Konture erhalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae32039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannyEdge(img):\n",
    "    sigma = 0.8         # Parameter, um die untere und obere Grenze zu variieren\n",
    "    m = np.median(img)  # Medianwert\n",
    "    lower = int(max(0, (1.0 - sigma) * m))   # lower threshold (Grenze)\n",
    "    upper = int(min(255, (1.0 + sigma) * m)) # upper threshold (Grenze)\n",
    "    imgCanny = cv2.Canny(img, lower, upper,L2gradient=True)  # OpenCV, die de Kante sucht\n",
    "    contours,hierarchy = cv2.findContours(imgCanny,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_TC89_L1)\n",
    "    while len(contours)<20:    # Schleife, um eine miniale Anzahl von Konturen zu erhalten\n",
    "        lower -= 10\n",
    "        upper -= 10\n",
    "        imgCanny = cv2.Canny(img, lower, upper,L2gradient=True)\n",
    "        contours,hierarchy = cv2.findContours(imgCanny,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_TC89_L1)\n",
    "    return imgCanny,contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6b2fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kante Erkennung\n",
    "imgCanny = cannyEdge(imgBlur)[0]\n",
    "\n",
    "cv2.imshow(\"Kanny\", imgCanny)\n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b01ff3",
   "metadata": {},
   "source": [
    "Wir können mit einer Funktion von OpenCV die Kanten auf dem Bild zeichnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0115a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours = cannyEdge(imgBlur)[1]\n",
    "cv2.drawContours(imgResized,contours,-1,(255,0,0),2)   # Alle Konture in Blau zeichen\n",
    "\n",
    "cv2.imshow(\"Kante\", imgResized) \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf7156",
   "metadata": {},
   "source": [
    "### 5. Umfang der größere Kontur\n",
    "\n",
    "Wir wollen in allen Konturen die größte Kontur herausziehen, un dann ihren Flächeninhalt berechnen. Dazu benutzen wir die Funktion *cv2.contourArea* von OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79e47b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flächeninhalt größter Kontur =  27812.0\n",
      "Länge größter Kontur =  834.482091665268\n"
     ]
    }
   ],
   "source": [
    "# Umfang von der größten Contour berechnen\n",
    "c_max = max(contours, key = cv2.contourArea)\n",
    "c_maxArea = cv2.contourArea(c_max)            # Flächeninhalt der größte Kontur \n",
    "c_maxLength = cv2.arcLength(c_max,True)       # Länge der größten Kontur\n",
    "cv2.drawContours(imgResized,[c_max],-1,(0,120,255),2)   # größte Kontur in Orange\n",
    "print('Flächeninhalt größter Kontur = ', c_maxArea)\n",
    "print('Länge größter Kontur = ', c_maxLength)\n",
    "cv2.imshow(\"Kante\", imgResized) \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076645a",
   "metadata": {},
   "source": [
    "### 6. Convexity Hull \n",
    "\n",
    "Wir wollen jetzt die sogenannte Konvexe Hülle (Convex Hull) berechnen und bzw. den Flächeninhalt dieser besonderen Kontur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86eca9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hull Area =  33362.5\n"
     ]
    }
   ],
   "source": [
    "# hull Kontur berechnen\n",
    "hull = cv2.convexHull(c_max)\n",
    "hullArea = cv2.contourArea(hull)       # Flächeninhalt der hull Kontur\n",
    "imgHull = cv2.drawContours(imgResized, [hull], -1, color=(0, 0, 255), thickness=5)  \n",
    "\n",
    "print('Hull Area = ', hullArea)\n",
    "cv2.imshow(\"Hull\", imgResized) \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb80edb",
   "metadata": {},
   "source": [
    "### 7. Solidity\n",
    "\n",
    "Wir können die sogenannte solidity mit der Formel $$solidity = \\displaystyle\\frac{c_{maxArea}}{hullArea}$$ definieren. Es ist der Quotient von dem Flächeninhalt der größten Kontur mit dem Flächeninhalt des Convexity Hulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa4c82c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solidity =  0.8336305732484076\n"
     ]
    }
   ],
   "source": [
    "solidity = c_maxArea/hullArea\n",
    "print('solidity = ',solidity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b8db5",
   "metadata": {},
   "source": [
    "### 8. Circularity\n",
    "\n",
    "Die Zirkularität ist mit der Formel $$circularity = \\displaystyle\\frac{4\\pi *c_{maxArea}}{c_{maxLength^2}}$$ definiert. Es ist der Quotient von dem Flächeninhalt der größten Kontur mit dem Länge der größten Kontur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a19a0813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circularity =  0.5018894224091988\n"
     ]
    }
   ],
   "source": [
    "# 8. Circularity\n",
    "circularity= 4*np.pi*c_maxArea/(c_maxLength**2)\n",
    "print('circularity = ',circularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67b4c6",
   "metadata": {},
   "source": [
    "### 9. Bounding box und Extent\n",
    "\n",
    "Wir können für jede Kontur ein bounding box definieren. Wir interessieren uns nur für die größte contour. Deshalb berechnen wir uns das Bounding Box nur für diese Kontur. Dazu ist das sogenannte **Extent** mit der Formel $$extent=\\displaystyle\\frac{ c_{maxArea}}{boundingBoxArea} $$ definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "664a7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of bounding box =  44697\n",
      "extent =  0.6222341544175224\n"
     ]
    }
   ],
   "source": [
    "# 9. bounding box und Extent\n",
    "x,y,length,heigth = cv2.boundingRect(c_max)\n",
    "cv2.rectangle(imgResized,(x,y),(x+length,y+heigth),(255,255,0),2)   # Bounding box in blue zeichen\n",
    "  \n",
    "boundingBoxArea = length*heigth\n",
    "extent = c_maxArea /  boundingBoxArea\n",
    "\n",
    "print('Area of bounding box = ',boundingBoxArea)\n",
    "print('extent = ',extent)\n",
    "\n",
    "cv2.imshow(\"Hull\", imgResized) \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e09e9b",
   "metadata": {},
   "source": [
    "### 10. Keypoints des Objektes finden\n",
    "\n",
    "Wir benutzen jetzt einen Algorithmus, der die sogenannte \"Keypoints\" in den Bilder finden soll. Dieser Algorithmus ist OBR benannt und wurde 2011 gegründet. [https://docs.opencv.org/master/d1/d89/tutorial_py_orb.html]\n",
    "\n",
    "In der CSV Datei werden wir die Anzahl von Keypoints schreiben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1512c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints: 419\n"
     ]
    }
   ],
   "source": [
    "orb = cv2.ORB_create()\n",
    "keyPoints, description = orb.detectAndCompute(imgCanny, None)\n",
    "imgKeypoints = cv2.drawKeypoints(imgCanny, keyPoints, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "print('Keypoints:', len(keyPoints))\n",
    "\n",
    "cv2.imshow(\"Keypoints\", imgKeypoints) \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d91643",
   "metadata": {},
   "source": [
    "### 11. Polygonale Schätzung\n",
    "\n",
    "Jetzt benutzen wir die Funktion *cv2.approxPolyDP*. Diese Funktion annährt eine Kontur mit einem Polynom. Wir werden hier auch die Anzahl an Punkte in der CSV Datei schreiben.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8cb0ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "c_maxLength = cv2.arcLength(c_max,True)                           # Länge der größten Kontur\n",
    "approx = cv2.approxPolyDP(c_max,0.005*c_maxLength,True)           # Koordinaten der Punkte der Schätzung\n",
    "print(len(approx))                                                # Anzahl von Punkten, die mit der Schätzung gefunden wurden\n",
    "cv2.polylines(imgResized, approx, True, (0,255,0), 6,lineType=8)  # Zeichen der Punkte in Grün\n",
    "\n",
    "cv2.imshow(\"Approx\", imgResized) \n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52294e40",
   "metadata": {},
   "source": [
    "## VI) CSV Datei schreiben\n",
    "\n",
    "### 1) Funktion für Merkmale\n",
    "Um eine CSV Datei zu schreiben programmieren wir zuerst eine Funktion, die die Merkmale einer Bilder berechnent und in einer Liste schreibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b796c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merkmale(imgPath,klasse):      # Argument : Pfad des Bildes und Klasse (0:Kamm oder 1:Bürste)\n",
    "    imgOrigin = cv2.imread(str(imgPath))\n",
    "    # Skalierung des Bildes\n",
    "    width = 500            # Breite in Pixel\n",
    "    height = 500            # Höhe in Pixel\n",
    "    dim = (width, height)   # neues Ausmaß der Bilder\n",
    "    \n",
    "    imgResized = cv2.resize(imgOrigin, dim, interpolation = cv2.INTER_AREA)\n",
    "    # 1. Normierung des Bildes\n",
    "    imgNormiert = cv2.normalize(imgResized,None,0,255,cv2.NORM_MINMAX) \n",
    "    \n",
    "    # 2. Grau Bild\n",
    "    imgGrau = cv2.cvtColor(imgNormiert,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 3. Bild filtern\n",
    "    imgBlur = cv2.bilateralFilter(imgGrau,9,80,80)\n",
    "    \n",
    "    # 4. Canny Bild und Konturen \n",
    "    imgCanny, contours = cannyEdge(imgBlur)\n",
    "        \n",
    "    # 5. Größte Kontur\n",
    "    c_max = max(contours, key = cv2.contourArea)\n",
    "    c_maxLength = cv2.arcLength(c_max,True)       # Länge der größten Kontur\n",
    "    c_maxArea = cv2.contourArea(c_max)\n",
    "    \n",
    "    # 6. Hull\n",
    "    hull = cv2.convexHull(c_max)\n",
    "    hullArea = cv2.contourArea(hull)\n",
    "    \n",
    "    # 7. Solidity\n",
    "    solidity = c_maxArea/hullArea\n",
    "    \n",
    "    # 8. Circularity\n",
    "    circularity= 4*c_maxArea/(c_maxLength**2)\n",
    "\n",
    "    # 9. bounding box und Extent\n",
    "    x,y,length,heigth = cv2.boundingRect(c_max)\n",
    "    boundingBoxArea = length*heigth\n",
    "    extent = c_maxArea /  boundingBoxArea\n",
    "                            \n",
    "    # 10. Keypoints des Objektes finden\n",
    "    orb = cv2.ORB_create()\n",
    "    keyPoints, description = orb.detectAndCompute(imgCanny, None)\n",
    "    keyPointsAnzahl = len(keyPoints)\n",
    "    \n",
    "    # 11. Polygonale Schätzung\n",
    "    approx = cv2.approxPolyDP(c_max,0.005*c_maxLength,True)\n",
    "    approxAnzahl = len(approx)           # Anzahl an Punkte in der polynomalen Schätzung\n",
    "    \n",
    "    # Merkmale in der Liste schreiben \n",
    "    merkmale = [c_maxLength,c_maxArea,circularity,solidity,extent,keyPointsAnzahl,approxAnzahl,klasse]\n",
    "    return merkmale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45330227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2251.7386873960495, 306.0, 0.00024140454292608128, 0.006599521211206246, 0.005047422680412371, 500, 31, 0]\n"
     ]
    }
   ],
   "source": [
    "# Prüfung der Funktion mit einem Bild\n",
    "print(merkmale(Buerste[3],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b15881",
   "metadata": {},
   "source": [
    "### 2. CSV Datei schreiben \n",
    "\n",
    "#### Bilder für das Verfahren\n",
    "\n",
    "Wir verwenden wir die Funktion *merkmale* auf jedes Bild von Kamm und Bürste, um die CSV Datei zu bilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37ac89c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "with open(\"merkmale.csv\", 'w', newline='') as f:\n",
    "    writer = csv.writer(f)                    # Erstellung des Schreibers\n",
    "    for path in Kamm:                         # Schleife über alle Bilder von Bürste\n",
    "        writer.writerow(merkmale(path,0))     # Neue Zeile mit den Merkmale addieren\n",
    "    for path in Buerste:                      # Schleife über alle Bilder von Bürste\n",
    "        writer.writerow(merkmale(path,1))     # Neue Zeile mit den Merkmale addiere\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7b1bb",
   "metadata": {},
   "source": [
    "#### Testbilder\n",
    "\n",
    "Wir wollen die verschiedene Verfahren mit Testbilder, d.h. Bilder, die extern von dem Verfahren sind. Dazu haben wir 3 Bilder von Kämme und 3 Bilder von Bürste in den Ordnern **Buerste_test** bzw. **Kamm_test** gestellt. Zuerst definieren die Pfade dieser Ordnern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba8df338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad der Bilder :  Bilder\\Testbilder\n",
      "Anzahl von Testbilder : 12\n"
     ]
    }
   ],
   "source": [
    "# Pfad der Testbilder\n",
    "testData_dir = pathlib.Path(r\"Bilder/Testbilder\")\n",
    "print(\"Pfad der Bilder : \", testData_dir)\n",
    "\n",
    "# Anzahl von Bilder\n",
    "test_image_count = len(list(testData_dir.glob('*/*.jpg')))\n",
    "print('Anzahl von Testbilder :', test_image_count)\n",
    "\n",
    "Buerste_test = list(testData_dir.glob('Buerste_test/*'))  # Ordner der Bilder von Bürste\n",
    "Kamm_test = list(testData_dir.glob('Kamm_test/*'))     # Ordner der Bilder von Bürste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0490c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# CSV Datei für die Testbilder\n",
    "with open(\"merkmale_test.csv\", 'w', newline='') as f:\n",
    "    writer = csv.writer(f)                    # create the csv writer\n",
    "    for path in Kamm_test:                      # Schleife über alle Bilder von Bürste\n",
    "        writer.writerow(merkmale(path,0))\n",
    "    for path in Buerste_test:                      # Schleife über alle Bilder von Bürste\n",
    "        writer.writerow(merkmale(path,1))\n",
    "    print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
